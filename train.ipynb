{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:20.061029Z",
     "start_time": "2017-11-10T05:48:20.041508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:20.903298Z",
     "start_time": "2017-11-10T05:48:20.220606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon as gl\n",
    "from mxnet import nd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:20.922143Z",
     "start_time": "2017-11-10T05:48:20.905731Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:20.939609Z",
     "start_time": "2017-11-10T05:48:20.924331Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_path= './data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:21.320868Z",
     "start_time": "2017-11-10T05:48:21.293306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_train(img):\n",
    "    '''\n",
    "    img is the mx.image.imread object\n",
    "    '''\n",
    "    img = img.astype('float32') / 255\n",
    "    random_shape = int(np.random.uniform() * 224 + 256)  \n",
    "    # random samplely in [256, 480]\n",
    "    aug_list = mx.image.CreateAugmenter(\n",
    "        data_shape=(3, 224, 224), resize=random_shape,\n",
    "        rand_mirror=True, rand_crop=True, \n",
    "        mean=np.array([0.4736, 0.4504, 0.3909]),                               \n",
    "        std=np.array([0.2655, 0.2607, 0.2650]))\n",
    "    \n",
    "    for aug in aug_list:\n",
    "        img = aug(img)\n",
    "    img = nd.transpose(img, (2, 0, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:21.667330Z",
     "start_time": "2017-11-10T05:48:21.642538Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_valid(img):\n",
    "    img = img.astype('float32') / 255.\n",
    "    aug_list = mx.image.CreateAugmenter(\n",
    "        data_shape=(3, 224, 224), \n",
    "        mean=np.array([0.4736, 0.4504, 0.3909]),                               \n",
    "        std=np.array([0.2655, 0.2607, 0.2650]))\n",
    "    \n",
    "    for aug in aug_list:\n",
    "        img = aug(img)\n",
    "    img = nd.transpose(img, (2, 0, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import DogDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T17:26:33.088858Z",
     "start_time": "2017-11-09T17:26:32.908167Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_json = './data/train.json'\n",
    "train_set = DogDataSet(train_json, im_path, transform_train)\n",
    "train_data = gl.data.DataLoader(train_set, batch_size=64, shuffle=True, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T17:26:33.123630Z",
     "start_time": "2017-11-09T17:26:33.091024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_json = './data/valid.json'\n",
    "valid_set = DogDataSet(valid_json, im_path, transform_valid)\n",
    "valid_data = gl.data.DataLoader(valid_set, batch_size=128, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:30.126987Z",
     "start_time": "2017-11-10T05:48:30.110288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = gl.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:30.146032Z",
     "start_time": "2017-11-10T05:48:30.129148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ctx = [mx.gpu(0), mx.gpu(1)]\n",
    "ctx = mx.gpu(0)\n",
    "num_epochs = 200\n",
    "lr = 0.1\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:30.219397Z",
     "start_time": "2017-11-10T05:48:30.148168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = gl.model_zoo.vision.resnet50_v2(classes=120)\n",
    "net.initialize(init=mx.init.Xavier(), ctx=ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:30.303491Z",
     "start_time": "2017-11-10T05:48:30.221456Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T05:48:30.900991Z",
     "start_time": "2017-11-10T05:48:30.309509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def get_acc(output, label):\n",
    "    pred = output.argmax(1)\n",
    "    correct = (pred == label).sum()\n",
    "    return correct.asscalar()\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_decay):\n",
    "    trainer = gl.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 89 or 159:\n",
    "            trainer.set_learning_rate = trainer.learning_rate * lr_decay\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, label in train_data:\n",
    "            bs = data.shape[0]\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with mx.autograd.record():\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(bs)\n",
    "            train_loss += loss.sum().asscalar()\n",
    "            correct += get_acc(output, label)\n",
    "            total += bs\n",
    "        writer.add_scalars('loss', {'train': train_loss / total}, epoch)\n",
    "        writer.add_scalars('acc', {'train': correct / total}, epoch)\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_correct = 0\n",
    "            valid_total = 0\n",
    "            valid_loss = 0\n",
    "            for data, label in valid_data:\n",
    "                bs = data.shape[0]\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "                valid_loss += nd.sum(loss).asscalar()\n",
    "                valid_correct += get_acc(output, label)\n",
    "                valid_total += bs\n",
    "            valid_acc = valid_correct / valid_total\n",
    "            writer.add_scalars('loss', {'valid': valid_loss / valid_total}, epoch)\n",
    "            writer.add_scalars('acc', {'valid': valid_acc}, epoch)\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train acc %f, Valid Loss: %f, Valid acc %f, \"\n",
    "                         % (epoch, train_loss / total,\n",
    "                            correct / total, valid_loss / valid_total, valid_acc))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, \"\n",
    "                         % (epoch, train_loss / total,\n",
    "                            correct / total))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T06:08:30.701520Z",
     "start_time": "2017-11-10T05:48:30.903152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.save_params('./res50.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
